{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Company","text":"<p>We are an Estonia-based IT consulting and administration team specializing in OpenStack cloud, Ceph storage and VyOS firewall. We have long-term competence in managing on-prem cloud, shared storage and firewall clusters. We will back you up when the rubber hits the road, so you don't have to!  </p> Generic information <p>Business name:  Wirt O\u00dc e-mail:     info@wirt.ee Register code:  16986693 IBAN (LHV): EE867700771010370923  SSH public key</p>"},{"location":"notes/","title":"Overview","text":""},{"location":"notes/#four-pillars-for-it-sadness","title":"Four pillars for IT sadness","text":"<p>Warning - nerd content! This section contains opinionated technical notes from real life. It's okay to agree, not agree, or philosophically acknowledge writers' viewpoints. Despite that, some commented code snippets may be helpful. </p>"},{"location":"notes/#compute-nodes","title":"Compute nodes","text":"<p>If it breaks or gets its upgrade, it is used and abused over and over to get out of as many ticks per cycle as possible. It is not a pet, even if it paid your kid's kindergarten and schooling and your own leisure time. And if it is worked many times over its expected lifetime, you try to sell its parts to recover some utilization costs. Totally underrated piece of everything that ships with cardboard coffins.</p>"},{"location":"notes/#networks-and-overlays","title":"Networks and overlays","text":"<p>In the good old days, there was a VLAN. And that's it.  Now, everything is on top of every other thing. Everyone expects excellent dual-stack performance, and MTU keeps shrinking.  Networking is so SDN that we tend to separate networks into \"hard\" and \"soft\". Soft networking is generated, and a hard network is something you type in with your fingertips to the switch console. Luckily, the physical network is still what it was. Only high-speed optic power consumption has blown through the roof. </p>"},{"location":"notes/#storage-tiers","title":"Storage tiers","text":"<p>A not long time ago, there were local storage, RAID and NAS/SAN boxes for LUNs you hacked together with LVM to get perf numbers for your DBA, who hates you. Now, it's shared erasure encoded multiprotocol mesh with online upgrades and failure domains. And if it explodes, you can keep all the pieces. And DBA still complains about service time. Regarding storage tearing and archival: \"King Tape is dead. Long live the King Tape.\" Sometimes, if you need to Petabyte your backyard, vendor lock is not a bad thing. Speaking about open source, it's worth mentioning that things are complicated, and sometimes, support contracts or wise men from the mountaintop are needed.  On a bad day, You take a half-block size 4M object and go on a pilgrimage. If it's a bad day on steroids, you can consult with your system administrator, e.g. with yourself.</p>"},{"location":"notes/#chaos-monkeys-eg-system-administratorsdevops","title":"Chaos monkeys (e.g. system administrators/DevOps)","text":"<p>We, I, are still the same. Old busted hardware, biased problem assessments, gut-based technology selections behind L1 support and paywall, and no repo-based CI. But this gut-based decision process still beats state-of-the-art language models. Of course, this \"Thing\" is a good company for a man who was brick-walled in with IBM's mainframe.</p>"},{"location":"notes/compute/","title":"Compute","text":""},{"location":"notes/compute/#hyperconverged-infrastructure","title":"Hyperconverged infrastructure","text":"<p>Everyone wants their cake and wants to eat it too. Expecialy when you have around 100 cores per multisocet socet machine with few TB of RAM loaded with tens of TB NVMEs. Request to get a shared cluster of everything is not so uncommon.  </p>"},{"location":"notes/compute/#numa","title":"NUMA","text":"<p>To avoid interfering with different services, it seems plausible to sort the running process. It also disciplines rouge clients and helps service providers with QOS management. Also, if it's overcommitted, it's much easier to communicate why things are slow.  </p> <pre><code>ps aux  | grep libvirt  | grep -v grep | awk '{print$2}' | while read line; do \n    echo taskset -cp \"${vm0}-${numa0_end},${vm1}-${numa1_end},${vm2}-${numa2_end},${vm3}-${numa3_end}\" \"${line}\"; done | sh 1&gt;/dev/null\n\nvirsh list  | awk '/inst/ {print $2}' | while read l;do \n    for i in $(seq 0 $(virsh dominfo $l |awk '/CPU\\(/ {print$2-1}')); do \n        virsh vcpupin $l $i \"${vm0}-${numa0_end},${vm1}-${numa1_end},${vm2}-${numa2_end},${vm3}-${numa3_end}\" 1&gt;/dev/null\n        #virsh vcpupin $l $i \"1-255\" 1&gt;/dev/null\n    done \ndone\n</code></pre>"},{"location":"notes/compute/#be-not-so-nice","title":"Be not so nice","text":"<p>If it waits behind storage, then the system slows down. Prioritize shared storage proceses.</p> <pre><code>ps -e -o pid,uid,ppid,pri,ni,cmd | awk '/ceph-osd/  &amp;&amp;  !/-20/ &amp;&amp; !/awk/ {print \"renice -n -20 -g\",$1,\";ionice -c 1 -n 1 -p\",$1}'  | sh\n</code></pre>"},{"location":"notes/network/firewall/","title":"VyOS firewall","text":""},{"location":"notes/network/firewall/#vyos-15x-iso-using-docker","title":"VyOS 1.5.x ISO using Docker","text":"<p>You can run the HA production cluster with this if you are brave (and experienced).  </p> <pre><code>git clone -b current --single-branch https://github.com/vyos/vyos-build\ncd vyos-build/\ndocker run --rm -it --privileged -v $(pwd):/vyos -w /vyos vyos/vyos-build:current bash\nvyos_bld@f6cbbb83c7d1:/vyos$ sudo make clean\nvyos_bld@5b5d83d5d5c0:/vyos$ sudo ./build-vyos-image  generic --architecture amd64 --build-by \"wirt\"\n</code></pre>"},{"location":"notes/network/generic/","title":"Generic","text":""},{"location":"notes/network/generic/#ip-commands","title":"IP commands","text":"<p>It tends to be universal across Linux systems. If nothing else works, it is a viable option to shut down the local network manager daemon and do the configuration manually. Also, make sure that the default route exists:  </p> <pre><code>ip route list table all\n</code></pre>"},{"location":"notes/network/generic/#martians","title":"Martians","text":"<p>If traffic to the interface is unexpected, you may get a silent drop. To avoid this drop, some relaxation and breathwork are needed:  </p> <pre><code>echo 1 &gt; /proc/sys/net/ipv4/conf/bond0/log_martians\nsysctl -w net.ipv4.conf.bond0.rp_filter=2\n</code></pre>"},{"location":"notes/network/generic/#policy-based-routing","title":"Policy based routing","text":"<p>Sometimes machine has more than one interface. Then, it's time to decide what goes where:</p> <pre><code>ip addr add ${ip}/${mask} dev ${dev}\nip link set dev ${dev} up\ntest -z \"$(grep ut_pub /etc/iproute2/rt_tables)\" &amp;&amp; echo \"666 pub\" &gt;&gt; /etc/iproute2/rt_tables\nip rule add from ${ip} table pub\nip rule add to ${ip} table pub\nip route add default via ${gw} dev ${dev} table pub\n</code></pre>"},{"location":"notes/network/generic/#systemd-networkd","title":"Systemd networkd","text":"<p>Over the years, every new distro upgrade has introduced some new ways to configure your network.  The situation was so bad that adding ip commands directly to the crontab @reboot line was quite common.  It was a pleasant surprise that the networkd actually worked and did not cause brain damage when configured. </p> <pre><code>cat  /etc/systemd/network/bond.network\n[Match]\nName=eno3*\n\n[Network]\nBond=bond0\n\ncat /etc/systemd/network/bond0.netdev\n[NetDev]\nName=bond0\nDescription=LAG/Bond to a switch\nKind=bond\nMACAddress=aa:aa:aa:aa:aa:aa\n\n[Bond]\nMode=802.3ad\nMIIMonitorSec=1\nLACPTransmitRate=slow\n\ncat /etc/systemd/network/bond0.network \n[Match]\nName=bond0\n\n[Network]\nVLAN=bond0.&lt;vlan tag&gt;\n\ncat /etc/systemd/network/bond0.&lt;vlan tag&gt;.netdev \n[NetDev]\nName=bond0.&lt;vlan tag&gt;\nKind=vlan\n\n[VLAN]\nId=&lt;vlan tag&gt;\n\ncat /etc/systemd/network/bond0.&lt;vlan tag&gt;.network\n[Match]\nName=bond0.&lt;vlan tag&gt;\n\n[Network]\nDHCP=yes\n</code></pre>"},{"location":"notes/network/generic/#systemd-hooks","title":"Systemd hooks","text":"<p>Sometimes, you need random scripts to run when the network connection status changes. The tool for the job in systemd world is networkd-dispatcher.</p> <pre><code>#!/bin/bash\n#workaroud for issue networkd backed netpaln that drops policy based routing and vlanX carring interface from br-vlan\n\nexport PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n\nbrctl addif br-vlan bond0\nif [[ -z \"$(ip rule list | grep br-public1)\" ]]; then\n    ip rule add from xxx.xx.xx.0/24 table br-public1\n    ip route add default via xxx.xx.xx.1 dev br-public table br-public1\n    ip rule add from yyy.yy.yy.0/24 table br-public2\n        ip route add default via yyy.yy.yy.1 dev br-public table br-public2\n    ip route flush cache\nfi\n</code></pre>"},{"location":"notes/network/lxb2ovs/","title":"OpenStack SDN","text":""},{"location":"notes/network/lxb2ovs/#openstack-ml2lxb","title":"OpenStack ML2/LXB","text":"<p>In 2016, the most mature way to get a self-service network up was a Linux-bridge-based agent-driven setup on top of V(X)LAN with HA provided by VRRP. Initially, the tenant network behaved nicely. SDN boot time started to look concerning when around 1000 ports needed configuration. Things got desperate when the port count rose to 6000 with SDN 40-hour boot time. Luckily, we found a simple workaround. Just add more agents in parallel and split VXLAN multicast group.  But the customer base keeps growing, and we had to buy the fastest cores under the sun with an unhealthy amount of RAM. Then we hit 18k port count. Common sense called us when we spent 32 cores and 256 GB of RAM per network controller to keep SDN up, free of charge, of course. It was time to migrate the Neutron mechanism driver! After careful consideration, the decision was to move directly to OVN. So the decision was to move from ML2/LXB to ML2/OVN. Easy, start the migration tool and take a cup of coffee. Unfortunately, no such path or tool existed for online migration. Our technical readiness to support the new SND at scale was rough at best, and all customers needed notification, especially those with stricter SLA's. So all this preliminary prep work took more than half of the year. Not to mention the initial testing, failing and re-testing phases.  </p>"},{"location":"notes/network/lxb2ovs/#openstack-ml2lxb-to-ml2ovn-migration","title":"OpenStack ML2/LXB to ML2/OVN migration","text":"<p>Anyway, when the stage was set up, the following steps played out within 16 hours:</p> <ol> <li>Back up all the configuration and databases.  </li> <li>Remove all network agents from inventory. Stop and disable running network agents like neutron-linuxbridge-agent, neutron-l3-agent, neutron-dhcp-agent and neutron-metadata-agent.</li> <li>Delete all unneeded bridges, VXLAN interfaces, and network namespaces lingering tap interfaces.</li> <li>Delete all unneeded iptables/nftables rules.</li> <li>Deploy OVN with your tool of choice!</li> <li>Since the database is the source of truth and doesn't care what cloud management system is pulling from it, you can refill (repair) the northbound database from it with neutron-ovn-db-sync-util</li> <li>It depends on your environment, but you may need to move the Geneve carrying interface to OVS and do some patching and VLAN tagging.</li> <li>Then lastly, update ports to reflect the new reality that vif_type is now ovs, not a bridge:</li> </ol> <pre><code>DB [(neutron)]&gt; update ml2_port_bindings set vif_type='ovs' where vif_type='bridge';\nDB [(neutron)]&gt; update networksegments set network_type='geneve' where network_type='vxlan';\n</code></pre>"},{"location":"notes/network/lxb2ovs/#results-and-conclutions","title":"Results and conclutions","text":"<p>Looks easy? Handful of steps and done? Guess again! If it blows up, it's spectacular. You can keep all the pieces. Let's assume that you are still employed or the proud business owner and need to roll back. It takes around a week, but you and your dog just ended a 16-hour shift. If rollaback is not an option, you may need to clean the southbound database line by line, comparing and hunting for UUID spaghetti with wrong values. Tracing veth pairs in OVS that, by design, don't show all traffic jumping between userspace and kernelspace, checking and rechecking MTUs on all hypervisors, and trying to ignore ever-louder customers' complaints about broken networking.</p> <p>But if it ends well, your network controllers are not hogged up anymore, boot times are acceptable, and you can silently watch how someone else's weekend (non-LAN) party final stages are played out on your way home.</p>"},{"location":"notes/storage/ceph/","title":"Ceph","text":""},{"location":"notes/storage/ceph/#get-ceph-backup","title":"Get CEPH backup","text":"<p>It is great when you have a backup or you don't destroy your network under an erasure-coded pool.</p> <pre><code>rbd export -p  pool volume-ad0ceef0-64ef-4050-afd6-3a12c13dd6be ./volume-ad0ceef0-64ef-4050-afd6-3a12c13dd6be.bac\n</code></pre>"},{"location":"notes/storage/ceph/#restore-ceph-from-backup","title":"Restore CEPH from backup","text":"<pre><code>rbd rm pool volume-ad0ceef0-64ef-4050-afd6-3a12c13dd6be\nrbd import ./volume-ad0ceef0-64ef-4050-afd6-3a12c13dd6be.bac  pool/volume-ad0ceef0-64ef-4050-afd6-3a12c13dd6be\n</code></pre>"},{"location":"notes/storage/ceph/#manipulate-ceph-block-storage-vm-disk","title":"Manipulate CEPH block storage (VM disk)","text":"<p>From time to time, you need to do some artwork inside VM. To do so, you first need to be able to mount RBD.</p> <pre><code>rbd export &lt;pool&gt;/&lt;volume&gt; /tmp/&lt;uuid&gt; #backup if needed\ndev=$(rbd map  &lt;pool&gt;/&lt;volume&gt; )\nsgdisk --print ${dev} #record current layout\nrbd showmapped\nrbd unmap ${dev}\n</code></pre>"},{"location":"notes/storage/generic/","title":"Generic","text":""},{"location":"notes/storage/generic/#disk-destroyer","title":"Disk Destroyer","text":"<p>There is no better tool to arrange your bits to oblivian. But if a precise cut is needed, some commands are more valuable than others. If your specific block size calculation is incorrect, you will lose your data!</p>"},{"location":"notes/storage/generic/#raid","title":"RAID","text":"<p>Metadata information is usually at the end of the device. If you want to re-use the device, you need to wipe it out. You have the option to wait and overwrite the entire disk:</p> <pre><code>root@demo:~# dd if=/dev/zero of=/dev/sdX bs=1M status=progress\n</code></pre> <p>Or zero out only parts Raid controller bothers to check:</p> <pre><code>root@demo:~# DEV='/dev/sdX'; dd if=/dev/zero of=$DEV bs=512 seek=$(( $(blockdev --getsz $DEV) - 1024 )) count=1024\n</code></pre>"},{"location":"notes/storage/generic/#software-raid-and-uefi","title":"Software RAID and UEFI","text":"<p>If RAID card is not present but you need FAT for EFI boot and some redundancy:  </p> <pre><code>/dev/sda1 is efi and /dev/sdb1 is empty\nroot@demo:~# dd if=/dev/sda1 of=/dev/sdb1\nroot@demo:~# mkdir /boot/efi2\nroot@demo:~# blkid /dev/sda1\n/dev/sda1: UUID=\"xxxx-xxxx\" TYPE=\"vfat\" PARTUUID=\"xxxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxx\"\nroot@demo:~# blkid /dev/sdb1\n/dev/sdb1: UUID=\"xxxx-xxxx\" TYPE=\"vfat\" PARTUUID=\"yyyyyyyyy-yyyy-yyyy-yyyy-yyyyyyyy\"\nroot@demo:~# cat /etc/fstab  | grep efi\nPARTUUID=xxxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxx  /boot/efi       vfat    umask=0077      0       1\nPARTUUID=xxxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxx  /boot/efi2      vfat    umask=0077      0       1\nroot@demo:~# efibootmgr -c -d /dev/sdb -p 1 -L \"Ubuntu-AltDrv\" -l '\\EFI\\ubuntu\\shimx64.efi'\n</code></pre>"},{"location":"notes/storage/generic/#copy-block-device-over-network","title":"Copy block device over network","text":"<p>Let's assume you already have a healthy dose of SSH in your bloodstream. Copy block device /dev/sdX content from one machine to another machine /dev/sdY with the command:</p> <pre><code>root@demo:~# ssh root@source.example \"dd if=/dev/sdX\" bs=1M | dd of=/dev/sdY bs=1M\n</code></pre>"},{"location":"notes/storage/generic/#swap-to-the-resque","title":"Swap to the resque","text":"<p>If you constantly get OOM killed and are happy to run your system randomly on glacier speed, then you can virtually add some RAM on the fly. 'pv' may be needed to avoid killing already slow storage. Example how to add 32G to swap:   </p> <pre><code>root@demo:~# dd if=/dev/zero | pv --rate-limit 60m | dd iflag=fullblock of=/swapfile bs=1G count=32 #32G swap\nroot@demo:~# dd if=/dev/zero of=/swapfile bs=4k count=8388608\nroot@demo:~# mkswap /swapfile\nroot@demo:~# chmod 0600 /swapfile\nroot@demo:~# /sbin/swapon /var/swapfile; #'swapoff' if needed\n</code></pre>"},{"location":"notes/storage/generic/#stretch-rocky-linux-partion-and-filesystem","title":"Stretch Rocky Linux partion and filesystem","text":"<pre><code>sfdisk --delete ${dev} 1\nsfdisk ${dev} &lt;&lt; EOF\n2048,,83\nEOF\nmount ${dev}p1 /mnt\nxfs_growfs /mnt\numount /mnt\n\n</code></pre>"},{"location":"notes/storage/generic/#stretch-ubuntu-linux-partion-and-filesystem","title":"Stretch Ubuntu Linux partion and filesystem","text":"<pre><code>#growpart /dev/sda 1 # if available\nsgdisk -d 1 /dev/rbdX\nsgdisk -N 1 /dev/rbdX\ne2fsck -y /dev/rbdXp1\nresize2fs /dev/rbdXp1\n\n#grow filesystem in VM\npartprobe /dev/sda\ngrowpart /dev/sda  1\nresize2fs /dev/sda1\n</code></pre>"},{"location":"notes/varia/logo/","title":"Company logo","text":""},{"location":"notes/varia/logo/#company-logo","title":"Company logo","text":"<p>Since entropy tends to increase when left unchecked, our company logo is an OpenSCAD code. Any ambiguities are potential sources of anticipation. Visual representation hints that we must view in all directions to keep systems afloat.</p>"},{"location":"notes/varia/trust/","title":"Basic trust","text":""},{"location":"notes/varia/trust/#verify-sha-256-checksum","title":"Verify SHA-256 checksum","text":"<p>To put an almost successful scam story short. Do not trust what you see! It may be a \"legitimate\" document from known sources. For the bare minimum, ask for data integrity verifications using the SHA-256 (SHA-2 family with a digest length of 256 bits). Data providers can so easily generate and publish hashes without even thinking about GDPR. Let's step through a simple example.</p> <p>First, generate some files with different content:</p> <pre><code>$ for i in {2345..2348};do date +\"%T.%6N\" &gt;  bill_${i}.pdf;done \n</code></pre> <p>Then shasum everything:</p> <pre><code>$ sha256sum *\nc46dd8a87ecabd1e2003d08bb7e0e8702e18767d6b126f4f00ff79b95cc73276  bill_2345.pdf\na1f0219644c86e4490a0a87b86a1717322dfb67c8148cc5205ca4ce8ac64b54e  bill_2346.pdf\n3e8d7257bfa1ed995e2ceaf61404b7ab83ac978f62d0a8f09cb2e1b8ed35c181  bill_2347.pdf\n6e1f15409e50c5c1253197971a1f04c01fe456a284f6d6c9e4f4a98e5044e2d7  bill_2348.pdf\n</code></pre> <p>And then let's generate the publically shareable file ( via the company webpage):</p> <pre><code>sha256sum * &gt; january_bills.txt\n</code></pre> <p>Now, we can distribute those files via a not-so-secure channel. And if the user wants to check file authenticity, it's easily doable:</p> <pre><code>$ sha256sum bill_2345.pdf\nc46dd8a87ecabd1e2003d08bb7e0e8702e18767d6b126f4f00ff79b95cc73276  bill_2345.pdf\n</code></pre> <p>If the file is tampered, then result is NOT what you published on your company webpage:</p> <pre><code>$ echo \"tampering\" &gt;&gt;  bill_2345.pdf\n$ sha256sum bill_2345.pdf\n867b5be7d12023f2268f5c9124eb5a518852195019fd3f067322963724b1d5be  bill_2345.pdf\n</code></pre>"},{"location":"notes/varia/DIY/disclaimer/","title":"DISCLAIMER","text":"<p>Behind every glitzy fa\u00e7ade is a name and face defined by actual things delivered. This subconer is for the company founders' DIY pet projects, to open up an authentic person you are dealing with. Be resourceful and stay away from the consumer stagnation path! Have the right to think with your head and repair your staff.</p> <p>DISCLAIMER: DO AT YOUR OWN RISK</p> <p>The information provided in this DIY project is for educational and informational purposes only. By following these instructions, you acknowledge and agree that:  </p> <ul> <li>You are undertaking this project entirely at your own risk</li> <li>You assume full responsibility for any injury, damage, or loss that may result from following these instructions</li> <li>You have the necessary skills, tools, and safety knowledge to complete this project safely</li> <li>You will follow all applicable safety guidelines, building codes, and local regulations</li> <li>You understand that working with tools, electrical components, chemicals, or other materials can be dangerous</li> <li>The author/creator assumes no liability for any accidents, injuries, property damage, or other losses that may occur</li> <li>You are responsible for using proper safety equipment and taking appropriate precautions</li> <li>If you are unsure about any aspect of this project, you will consult with qualified professionals before proceeding  </li> </ul> <p>By proceeding with this project, you acknowledge that you have read, understood, and agreed to this disclaimer.</p>"},{"location":"notes/varia/DIY/3d/","title":"3D printing and design","text":""},{"location":"notes/varia/DIY/3d/#placeholder-for-my-3d-printing-projects-documentation","title":"Placeholder for my  3D printing projects documentation.","text":""},{"location":"notes/varia/DIY/aquaponic/","title":"Fish tank","text":""},{"location":"notes/varia/DIY/aquaponic/#placeholder-for-my-aquaponic-project-documentation","title":"Placeholder for my aquaponic project documentation.","text":""},{"location":"notes/varia/DIY/bicycle/","title":"Electrified bicycles","text":""},{"location":"notes/varia/DIY/bicycle/#current-state","title":"Current state.","text":"<p>In the early days of brushless DC motors, I developed a mild need to build an electrified bicycle, since it is convenient in a city to transport kids and smaller goods. My finalised utility is here. The only maintenance it needed for the last 5000 km was occasional rainwash. This thing has all-wheel drive mode and tank turn capabilities. </p>"},{"location":"notes/varia/DIY/bicycle/#attempt-one","title":"Attempt one","text":"<p>Let's step through a complete chain of failures set by the initial goal. Since my pockets were not very deep, I had to think about how to get things done under a nonexistent budget.  My first motor was a car generator. I drilled out a regular electromagnet and replaced it with neodymium magnets. Now it can be called a motor. And then I fitted a regular bicycle gear on the shaft. </p> <p>This setup has three problems. The magnetic field was weak, heavy, and had no freewheeling (directly connected to the pedals).  Since BLDC wants switching in electronics, I had to wire hardware and write code to get the motor to spin. Battery technology was not there, and I had to use a second-hand, super-heavy, regular 12V car battery. To cut BS, this thing was not convenient to use. I accepted losses and paused. Procjet state was recorded here</p>"},{"location":"notes/varia/DIY/bicycle/#attempt-two","title":"Attempt two","text":"<p>The second attempt was made when I could buy an el-cheapo BLDC controller and a skateboard motor. The idea was to print out the nylon gravity pusher and the drag front wheel. I wanted to get around 50W of power transfer from it. Unfortunately, it started bouncing on the wheel due to irregularities. Then I pulled it towards the front wheel, got my happy 2 km and blew the controller. Luckily, my self-made battery survived because I did not forget to install a proper fuse. </p>"},{"location":"notes/varia/DIY/bicycle/#attempt-three","title":"Attempt three","text":"<p>Since pockets had grown deeper and the world around me had evolved, I managed to buy my first \"proper\" hub motor and controller. It turned out that starting from a standstill (hall sensors) and using an electronic brake were essential, mainly because speed (weight) increased, and brake pad and rim wear were significant. </p> <p>I upgraded batterys and got around 120 km range out of it. </p> <p>Then, after a significant number of cycles ( around 17 years). Bikeframe started to show its age. Initially, the front fork fell off. Then I discovered small cracks on the seatpost. I repaired and replaced everything, but the ageing issues did not go away.   </p> <p>Then winter happanes - again. </p>"},{"location":"notes/varia/DIY/bicycle/#final-attempt","title":"Final attempt","text":"<p>After another reality check, I started to plan my new two-wheeler.  Requirements were:</p> <ol> <li>Maintenance free</li> <li>Robust frame, steel fork</li> <li>Comfort riding position</li> <li>All wheel drive, e-brake</li> <li>Bicycle, by its nature</li> </ol> <p>First, I considered recumbent bikes, but I gave up because of their rarity.</p> <p>Then no one will sell me a decent quality diamond-framed bicycle with a belt drive. High-end bicycles were built for racing. Regular city bikes were built to compete on price. It took half a year and countless rejections for custom-built bicycle manufacturers until I found 99% what I wanted. The only thing I had to do was lace the motor myself. Build a battery, install a front rack for it ( no bending wires) and hope for the best.</p> <p> </p> <p>I decided to stick with my proven e-bike controller provider. I accidentally purchased a lower-voltage-rated controller during the COVID supply turbulence. I managed to get it to run, but just in case, I contacted the seller since the setup was too hard for a kit. The company owner wrote back to notify me that I have a 50% chance of blowing up MOSFETs \u2014 yet another controller swap. Then I discovered that my new battery BMS was weak. This one was luckily fixable in the e-bike software by doing a 0. something seconds softer start. After that, I had to build a PAS sensor inside the gearbox. The initial idea to let the belt drive the PAS looked clumsy. But there was a way to fit everything inside the gearbox's removable cover cap. After numerous failed prints, I got it done. Now the final touch was to set up reasonable limits for this beast and hit the road.  </p>"},{"location":"notes/varia/DIY/boiler/","title":"Wood boiler","text":""},{"location":"notes/varia/DIY/boiler/#placeholder-for-my-house-central-heating-project-documentation","title":"Placeholder for my house central heating project documentation.","text":""},{"location":"notes/varia/DIY/furniture/","title":"Wood furniture","text":""},{"location":"notes/varia/DIY/furniture/#placeholder-for-various-pieces-of-wood-furniture","title":"Placeholder for various pieces of wood furniture.","text":""},{"location":"notes/varia/DIY/mower/","title":"Lawn mower","text":""},{"location":"notes/varia/DIY/mower/#placeholder-for-my-lawn-mower-project-documentation","title":"Placeholder for my lawn mower project documentation.","text":""},{"location":"notes/varia/DIY/solar/","title":"Solar installations","text":""},{"location":"notes/varia/DIY/solar/#placeholder-for-my-off-grid-solar-panel-installation-project-documentation","title":"Placeholder for my off-grid solar panel installation project documentation.","text":""},{"location":"offers/","title":"Overview","text":""},{"location":"offers/#our-speciality","title":"Our speciality","text":"<ul> <li>OpenStack based cloud infrastructure deployment and administration at scale</li> <li>Ceph storage setup, maintenance and monitoring best practices</li> <li>VyOS firewall ruleset design and upgrade procedures</li> </ul>"},{"location":"offers/ceph/","title":"Ceph","text":""},{"location":"offers/ceph/#shared-vs-local-storage","title":"Shared vs. local storage","text":"<p>Local NVME storage is fast and finite in size. Shared storage allows moderate speedy space aggregation from all storage nodes, with the cost of events in one shared storage node, affecting the entire cluster. However, with shared storage, you can migrate VM online from one hypervisor to another.  </p>"},{"location":"offers/ceph/#placement","title":"Placement","text":"<p>Ceph fault tolerance depends on its disk's physical location. It is essential to figure out what fault tolerance assumptions are. Then, you can decide what you can lose (datacenter, rack, host, disk). It has to be a conscious decision.  </p>"},{"location":"offers/ceph/#replicated-vs-erasure-encoded","title":"Replicated vs. erasure encoded","text":"<p>Replicated is what the name says: \"Replicated X times.\" Generally, 3x is fine. Erasure encoding is an entirely different setup. On its basic level, a decision is needed on how many coding junks and data junks are required. Let's use K data junks and M coding junks. You need to use one coding junk for two data junks to set up a minimal supported EC pool. In literature, it is called the \"k=2 m=1\" schema.  </p>"},{"location":"offers/ceph/#fault-tolerance","title":"Fault tolerance","text":"<p>Let's take a trivial example. Cloud storage is 3x replicated. Losing one disk is not a significant event. Losing two disks prioritizes maximum recovery IOPS. Losing three disks means downtime and restoring from backup.</p>"},{"location":"offers/ceph/#block-vs-file-vs-object","title":"Block vs. file vs. object","text":"<p>Under the hood, it's an object storage. However, the translation layer allows it to present as a block, file or object. For OpenStack VM, it's a block device. For the journal log collector, it is a file. For S3 and Swift, it is an object.</p>"},{"location":"offers/openstack/","title":"OpenStack","text":""},{"location":"offers/openstack/#benefits-of-owning-an-on-prem-cloud-infrastructure","title":"Benefits of owning an on-prem cloud infrastructure","text":"<p>It's entirely under your control. The entire hardware and software lifecycle depends on your decisions. OpenStack itself, is set of services: compute, network, storage and controller plane (databases, proxies, identity, caching, UI, MQ).</p>"},{"location":"offers/openstack/#basic-on-prem-openstack-cloud-bundle","title":"Basic on-prem OpenStack cloud bundle","text":"<ul> <li>Server room with adequate power and cooling  </li> <li>Network stack  </li> <li>Compute, storage and controller nodes  </li> <li>OpenStack software installation  </li> <li>Plans for upgrade and disaster recovery  </li> </ul>"},{"location":"offers/openstack/#fault-tolerance","title":"Fault tolerance","text":"<p>From our point of view, a single piece of hardware is more resilient than a stack of rust. The same applies to software instances. But if it fails, then it's difficult or impossible to recover. On reasonable-sized OpenStack installation, something is always in a failed state or under maintenance. However, you need to know how fault-tolerant your installation is.  </p> <p>Let's look at two trivial examples. In the first example, the controller plane database is a 3x replica. Losing one replica is not a significant event. However, the split-brain condition can occur like any other quorum-based system. In the second example, the networking interface or switch malfunctions. Losing one network path won't affect installation. However, things would be sad if the design decision was to run a hyper-converged cloud infrastructure on a single interface.</p>"},{"location":"offers/openstack/#timetable","title":"Timetable","text":"<p>The inertia of decently sized OpenStack-based cloud solutions is quite massive. The fresh deployment timeline mostly depends on the components required. For basic SDN and shared storage upgrades, roughly 70% of the time will go to pre-upgrade test-prepare tasks and 30% to post-upgrade tasks and emerging fixes.   </p>"},{"location":"offers/openstack/#stack-of-all-things","title":"Stack of all things","text":"<p>As the name OpenStack suggests, it's a stack of things. We help you to make the correct choices in that stack.  </p>"},{"location":"offers/vyos/","title":"VyOS","text":""},{"location":"offers/vyos/#design","title":"Design","text":"<p>Like it or not, the firewall/router ruleset will be the most up-to-date documentation about your network configuration. If the firewall ruleset is modest, you will probably get away with linear code. You will likely notice that adding new rules is difficult when the ruleset needed refactoring yesterday. One change will break something else, and a hotfix unexpectedly drops traffic. The unstructured rule's worst-case time complexity is O(n), and they are also unmaintainable.  </p>"},{"location":"offers/vyos/#configuration","title":"Configuration","text":"<p>All installations are different. However, since the VyOS configuration is text-based, it seems reasonable to keep it in Git or some other versioning system. Deploying code via Ansible makes it less error-prone. Unfortunately, deleting or replacing rules in an ordered manner is still manual labour.     </p>"},{"location":"offers/vyos/#redundancy","title":"Redundancy","text":"<p>You can set up firewalls as primary and backup or load balance between firewalls. The first option is the simplest to set up. The second option requires serious mental gymnastics from network administration, but your firewall configuration can not be out of sync or misconfigured, or it simply does not function. It also reduces the risk that when the primary firewall fails, you will discover that the backup had also failed many months ago.  </p>"},{"location":"offers/vyos/#routing","title":"Routing","text":"<p>Every host that needs to go somewhere needs to find its next hop. Network packets will be lifted from one interface to another, masked, filtered, or even dropped silently according to the ruleset. When you have dynamic routing, things will get more complicated. Add IPv6 into the blender, and you double things that need your attention. Cascade routing from one protocol to another, tray to conntrack HA firewalls state and fast path flows to get the perfect overheated blend for Friday night.</p>"},{"location":"offers/vyos/#firewall","title":"Firewall","text":"<p>Commonly, the firewall is blamed for all sorts of computing issues first. Unfortunately, a combination of things may cause unimaginable issues. </p>"},{"location":"profile/","title":"Profile","text":""},{"location":"profile/#when-to-consider-us","title":"When to consider us","text":"<p>We are happy to think along if you are within those 10% that need a tailor's suit. It's quite likely that academic infrastructure fits best, but from our experience, initial design choices are complicated, and mistakes are super hard to turn down the road. In the long run, the initial assessment may bring the price down significantly. </p>"},{"location":"profile/#experience","title":"Experience","text":"<p>Our OpenStack cloud journey started in 2016 with the Mitaka release. Ceph storage utilisation started around 2017 with Jewel release. Mainly because commercial, supported solution IOPS was lower than expected.  VyOS HA firewall started in 2022 out of necessity from Equuleus. The previous corporate firewall support price was way beyond imagination. Since everything above is always live upgraded, we have solid recipes that work in real life. Integration is the keyword. The software stack that creates functional deployment is massive.  </p>"},{"location":"profile/#team","title":"Team","text":"<p>Academia PhD graded, well paid technical support personnel. We politely refuse when a conflict of interest or massive academic infrastructure suits you better.  </p>"},{"location":"profile/#requests","title":"Requests","text":"<p>info@wirt.ee in English or Estonian.  </p>"},{"location":"profile/#pricing","title":"Pricing","text":"<p>A Taylor's suit solution is from 74 \u20ac/h + VAT. If a regular suit fits well, academia prices will start from 60 \u20ac/h, mostly self-service if you can help yourself. So, you will be charged only for the hardware you use. Academia is a non-profit, so as long as you are able to use keywords like \"Innovation\", \"Collaboration\", and \"Industry\", most minor infrastructure adjustments are free of charge. If you are lucky, you will get the same person to guide you through the infrastructure setup process in academia.</p>"}]}